17128	yunhong_zhou dennis_wilkinson robert_schreiber rong_pan	largescale parallel collaborative filtering for the netflix prize	many recommendation system suggest item to user by utilize the technique of collaborative filter lrb cf rrb base on historical record of item that the user have view purchase or rate two major problem that most cf approach have to resolve be scalability and sparseness of the user profile in this paper we describe alternatingleastsquare with weightedregularization lrb alswr rrb a parallel algorithm that we design for the netflix prize a largescale collaborative filter challenge we use parallel matlab on a linux cluster as the experimental platform we show empirically that the performance of alswr monotonically increase with both the number of feature and the number of als iteration we alswr apply to the netflix dataset with 1000 hide feature obtain a rmse score of 08985 which be one of the best result base on a pure method combine with the parallel version of other known method we achieve a performance improvement of 591 over netflix s own cinematch recommendation system we method be simple and scale well to very large dataset doi 101007 978354068880832 mapreduce netflix sgd dal factorization	AAIM	HP_Labs Palo_Alto 94304
17746	robert_schreiber	a introduction to hpf		The_Data_Parallel_Programming_Model	
50246	robert_schreiber shail_aditya b._ramakrishna_rau vinod_kathail scott_a._mahlke santosh_g._abraham greg_snider	highlevel synthesis of nonprogrammable hardware accelerators	asic highlevel synthesis the picon system automatically synthesize embedded nonprogrammable accelerator to be use as coprocessor for function express as loop nest in c the output be synthesizable vhdl that define the accelerator at the register transfer level lrb rtl rrb the system generate a synchronous array of customize vliw lrb verylong instruction word rrb processor they controller local memory and interface the system also modify the user s application software to make use of the generate accelerator the user indicate the throughput to be achieve by specify the number of processor and they initiation interval in experimental comparison picon design be slightly more costly than handdesigned accelerator with the same performance abstract the picon system automatically synthesize embedded nonprogrammable accelerator to be use as coprocessor for function express as loop nest in c the output be synthesizable vhdl that define the accelerator at the register transfer level lrb rtl rrb the system generate a synchronous array of customize vliw lrb verylong instruction word rrb processor they controller local memory and interface the system also modify the user s application software to make use of the generate accelerator the user indicate the throughput to be achieve by specify the number of processor and they initiation interval in experimental comparison picon design be slightly more costly than handdesigned accelerator with the same performance doi 101109 asap 2000862383 accelerator nest ing pico npa	ASAP	
77536	alain_darte robert_schreiber gilles_villard	latticebased memory allocation	this work extend	CASES	
253373	robert_schreiber	manycore in the future		HPCC	HP_Labs
408675	alain_darte robert_schreiber b._ramakrishna_rau frederic_vivien	a constructive solution to the juggling problem in processor array synthesis		IPDPS	
414981	robert_schreiber	support for irregular computation in high performance fortran lrb abstract rrb		IRREGULAR	
419684	dana_vantrease robert_schreiber matteo_monchiero moray_mclaren norman_p._jouppi marco_fiorentino al_davis nathan_l._binkert raymond_g._beausoleil jung_ho_ahn	corona system implication of emerge nanophotonic technology	we expect that manycore microprocessor will push performance per chip from the 10 gigaflop to the 10 teraflop range in the come decade to support this increase performance memory and intercore bandwidth will also have to scale by order of magnitude pin limitation the energy cost of electrical signaling and the nonscalability of chiplength global wire be significant bandwidth impediment recent development in silicon nanophotonic technology have the potential to meet these off and onstack bandwidth requirement at acceptable power level corona be a 3d manycore architecture that use nanophotonic communication for both intercore communication and offstack communication to memory or io device its peak floatingpoint performance be 10 teraflop dense wavelength division multiplex optically connect memory module provide 10 terabyte per second memory bandwidth a photonic crossbar fully interconnect its 256 lowpower multithreaded core at 20 terabyte per second bandwidth we have simulated a 1024 thread corona system run synthetic benchmark and scale version of the splash2 benchmark suite we believe that in comparison with a electricallyconnected manycore alternative that use the same onstack interconnect power corona can provide 2 to 6 time more performance on many memory intensive workload while simultaneously reduce power doi 101145 13946081382135 cmp onchip crossbar arbitration photonic noc	ISCA	Univ._of_Wisconsin_-_Madison Madison WI
482983	siddhartha_chatterjee john_r._gilbert robert_schreiber	the alignmentdistribution graph	implement a dataparallel language such as fortran 90 on a distributedmemory parallel computer require distribute aggregate datum object lrb such as array rrb among the memory module attach to the processor the mapping of object to the machine determine the amount of residual communication need to bring operand of parallel operation into alignment with each other we present a program representation call	LCPC	
482985	siddhartha_chatterjee robert_schreiber thomas_j._sheffler john_r._gilbert	array distribution in dataparallel programs	we consider distribution at compile time of the array datum in a distributedmemory implementation of a dataparallel program write in a language like fortran 90 we allow dynamic redistribution of datum and define a heuristic algorithmic framework that choose distribution parameter to minimize a estimate of program completion time we represent the program as a alignmentdistribution graph we propose a divideandconquer algorithm for distribution that initially assign a common distribution to each node of the graph and successively refine this assignment take computation realignment and redistribution cost into account we explain how to estimate the effect of distribution on computation cost and how to choose a candidate set of distribution we present the result of a implementation of we algorithm on several test problem doi 101007 bfb0025872 partitioning divideandconquer algorithm distribution map	LCPC	
483274	thomas_j._sheffler robert_schreiber william_pugh john_r._gilbert siddhartha_chatterjee	efficient distribution analysis via graph contraction	alignment and distribution of datum by a optimize compiler be a dream of both manufacturer and user of parallel computer the distribution problem have be formulate as a npcomplete graph optimization problem the graph arise in application be large and the optimization problem do not lend itself to traditional heuristic optimization technique in this paper we improve some earlier result on method that use graph contraction to reduce the size of a distribution problem we report on a experiment use seven example program that show these contraction operation to be effective in practice we obtain from 60 to 99 percent reduction in problem size the larger number be more typical without loss of solution quality doi 101007 bfb0014212 nasa contraction operation os data distribution parallel computer	LCPC	
546078	siddhartha_chatterjee john_r._gilbert robert_schreiber shang-hua_teng	automatic array alignment in dataparallel programs	dataparallel language like fortran 90 express parallelism in the form of operation on datum aggregate such as array misalignment of the operand of a array operation can reduce program performance on a distributedmemory parallel machine by require nonlocal datum access determine array alignment that reduce communication be therefore a key issue in compile such language we present a framework for the automatic determination of array alignment in dataparallel language such as fortran 90 we language model handle array sectioning reduction spread transposition and mask operation we decompose alignment function into three constituent axis stride and offset for each of these subproblem we show how to solve the alignment problem for a basic block of code possibly contain common subexpression alignment be generate for all array object in the code both name program variable and intermediate result the alignment obtain by we algorithm be more general than those provide by the 8220 ownercompute 8221 rule finally we present some idea for deal with control flow replication and dynamic alignment that depend on loop induction variable doi 101145 158511158517 array alignment automatic determination data distribution loop nest	POPL	
548343	siddhartha_chatterjee john_r._gilbert fred_j._e._long robert_schreiber shang-hua_teng	generating local address and communication set for dataparallel programs	generating local address and communication set be a important issue in distributedmemory implementation of dataparallel language such as high performance fortran we show that for a array italic a italic affinely align to a italic template italic that be distribute across italic p italic processor with a italic cyclic lrb k rrb italic distribution and a computation involve the regular section italic a lrb l h s rrb italic the local memory access sequence for any processor be characterize by a finite state machine of at most italic k italic state we present fast algorithm for compute the essential information about these state machine and extend the framework to handle multidimensional array we also show how to generate communication set use the state machine approach performance result show that this solution require very little runtime overhead and acceptable preprocessing time doi 101145 155332155348 hpf fsm communication set array element stride	PPOPP	
548378	alain_darte robert_schreiber	a lineartime algorithm for optimal barrier placement	we want to perform compiletime analysis of a spmd program and place barrier in it to synchronize it correctly minimize the runtime cost of the synchronization this be the barrier minimization problem no full solution to the problem have be give previouslyhere we model the problem with a new combinatorial structure a nested family of set of circular interval we show that barrier minimization be equivalent to find a hierarchy of minimum cardinality point set that cut all interval for a single loop model as a simple family of circular interval a lineartime algorithm be know we extend this result find a lineartime solution for nested circular interval family this result solve the barrier minimization problem for general nested loop doi 101145 10659441065949 lineartime algorithm	PPOPP	
549090	john_r._gilbert robert_schreiber	optimal datum placement for distribute memory architecture		PPSC	
549489	edward_rothberg robert_schreiber	efficient parallel sparse cholesky factorization		PPSC	
570313	alina_ene william_horne nikola_milosavljevic prasad_rao robert_schreiber robert_endre_tarjan	fast exact and heuristic method for role minimization problem	we describe several new bottomup approach to problem in role engineering for rolebased access control lrb rbac rrb the salient problem be all npcomplete even to approximate yet we find that in instance that arise in practice these problem can be solve in minute we first consider role minimization the process of find a smallest collection of role that can be use to implement a preexisting usertopermission relation we introduce fast graph reduction that allow recovery of the solution from the solution to a problem on a smaller input graph for we test case these reduction either solve the problem or reduce the problem enough that we find the optimum solution with a lrb worstcase rrb exponential method we introduce lower bound that be sharp for seven of nine test case and be within 34 on the other two we introduce and test a new polynomialtime approximation that on average yield 2 more role than the optimum we next consider the related problem of minimize the number of connection between role and user or permission and we develop effective heuristic method for this problem as well finally we propose method for several related problem doi 101145 13778361377838 role mining ment rbac ber access control num approximate nphard	SACMAT	Hewlett-Packard Princeton NJ
574687	david_h._bailey e._barszcz j._t._barton d._s._browning robert_l._carter leonardo_dagum rod_fatoohi paul_o._frederickson t._a._lasinski robert_schreiber horst_d._simon v._venkatakrishnan sisira_weeratunga	the nas parallel benchmark summary and preliminary result	a new set of benchmark have be develop for the performance evaluation of highly parallel supercomput doi 101145 125826125925	SC	Numerical_Aerodynamic_Simulation_(NAS)_Syst._Div. NASA_Ames_Res._Center Moffett_Field CA USA
574853	siddhartha_chatterjee john_r._gilbert robert_schreiber	mobile and replicate alignment of array in dataparallel program	when a dataparallel language like fortran 90 be compile for a distributedmemory machine aggregate datum object lrb such as array rrb be distribute across the processor memory the mapping determine the amount of residual communication need to bring operand of parallel operation into alignment with each other a common approach be to break the mapping into two stage first a alignment that map all the object to a abstract template and then a distribution that map the template to the processor we solve two facet of the problem of find alignment that reduce residual communication we determine alignment that vary in loop and object that should have replicate alignment we show that loopdependent mobile alignment be sometimes necessary for optimum performance and we provide algorithm with which a compiler can determine good mobile alignment for object within do loop we also identify situation in which replicate alignment be either require by the program itself lrb via spread operation rrb or can be use to improve performance we propose a algorithm base on network flow that determine which object to replicate so as to minimize the total amount of broadcast communication in replication this work on mobile and replicate alignment extend we earlier work on determine static alignment doi 101145 169627169764 nasa adg alignment phase arbitrary control flow optimum	SC	NASA_Ames_Res._Center Moffett_Field CA USA
575398	edward_rothberg robert_schreiber	improve load distribution in parallel sparse cholesky factorization	compare to the customary columnoriented approach blockoriented distributedmemory sparse cholesky factorization benefit from a asymptotic reduction in interprocessor communication volume and a asymptotic increase in the amount of concurrency that be expose in the problem unfortunately blockoriented approach lrb specifically the block fanout method rrb have suffer from poor balance of the computational load as a result achieve performance can be quite low this paper investigate the reason for this load imbalance and propose simple block mapping heuristic that dramatically improve it the result be a roughly 20 increase in realize parallel factorization performance as demonstrate by performance result from a intel paragon 8482 system we have achieve performance of nearly 32 billion float point operation per second with this technique on a 196node paragon system cholesky factorization sparse cholesky fanin parallel solver	SC	Research_Institute_for_Advanced_Computer_Science NASA_Ames_Research_Center Moffett_Field CA
579226	bei_wang jeff_m._phillips robert_schreiber dennis_wilkinson	spatial scan statistics for graph clustering	in this paper we present a measure associate with detection and inference of statistically anomalous cluster of a graph base on the likelihood test of observe and expect edge in a subgraph this measure be adapt from spatial scan statistics for point set and provide quantitative assessment for cluster we discuss some important property of this statistic and its relation to modularity and bregman divergence we apply a simple clustering algorithm to find cluster with large value of this measure in a variety of realworld datum set and we illustrate its ability to identify statistically significant cluster of select granularity 1 introduction numerous technique have be propose for identify cluster in large network but it have prove difficult to meaningfully and quantitatively assess they especially from realworld datum whose clustering structure be a priori unknown one of the key challenge encounter by previous clustering method be rating or evaluate the result in large network manual evaluation of the result be not feasible and previous study have thus turn to artificially create graph with known structure as a test set however many method especially those in which the number of cluster must be specify as a algorithm parameter give very poor result when apply to realworld graph which often have a highly skewed degree distribution and overlap complex clustering structure lsb 18 33 rsb doi 101137 1978161197278866 realworld data subgraph statistic number of cluster large network	SDM	
652728	nina_mishra robert_schreiber isabelle_stanton robert_endre_tarjan	cluster social networks	social network be ubiquitous the discovery of closeknit cluster in these network be of fundamental and practical interest exist clustering criterion be limit in that cluster typically do not overlap all vertex be cluster andor external sparsity be ignore we introduce a new criterion that overcome these limitation by combine internal density with external sparsity in a natural way a algorithm be give for provably find the cluster provide there be a sufficiently large gap between internal density and external sparsity experiment on real social network illustrate the effectiveness of the algorithm doi 101007 97835407700465 conductance subgraph cut clustering algorithm community detection	WAW	
768287	robert_schreiber	on systolic array method for band matrix factorizations		BIT	
768288	robert_schreiber wei-pai_tang	on on systolic array for update the cholesky factorization		BIT	
806937	vinod_kathail shail_aditya robert_schreiber b._ramakrishna_rau darren_c._cronquist mukund_sivaraman	pico automatically designing custom computers		IEEE_Computer	
910094	steven_w._hammond robert_schreiber	efficient iccg on a share memory multiprocessor		International_Journal_of_High_Speed_Computing	
910133	robert_schreiber	a assessment of the connection machine		International_Journal_of_High_Speed_Computing	
988487	siddhartha_chatterjee john_r._gilbert fred_j._e._long robert_schreiber shang-hua_teng	generating local address and communication set for dataparallel programs	generating local address and communication set be a important issue in distributedmemory implementation of dataparallel language such as high performance fortran we show that for a array italic a italic affinely align to a italic template italic that be distribute across italic p italic processor with a italic cyclic lrb k rrb italic distribution and a computation involve the regular section italic a lrb l h s rrb italic the local memory access sequence for any processor be characterize by a finite state machine of at most italic k italic state we present fast algorithm for compute the essential information about these state machine and extend the framework to handle multidimensional array we also show how to generate communication set use the state machine approach performance result show that this solution require very little runtime overhead and acceptable preprocessing time doi 101145 155332155348 hpf fsm communication set array element stride	J._Parallel_Distrib._Comput.	
988488	siddhartha_chatterjee john_r._gilbert leonid_oliker robert_schreiber thomas_j._sheffler	algorithm for automatic alignment of array	aggregate datum object lrb such as array rrb be distribute across the processor memory when compile a dataparallel language for a distributedmemory machine the mapping determine the amount of communication need to bring operand of parallel operation into alignment with each other a common approach be to break the mapping into two stage a alignment that map all the object to a abstract template follow by a distribution that map the template to the processor this paper describe algorithm for solve the various facet of the alignment problem axis and stride alignment static and mobile offset alignment and replication labeling we show that optimal axis and stride alignment be npcomplete for general program graph and give a heuristic method that can explore the space of possible solution in a number of way we show that some of these strategy can give better solution than a simple greedy approach propose earlier we also show how local graph contraction can reduce the size of the problem significantly without change the best solution this allow more complex and effective heuristic to be use we show how to model the static offset alignment problem use linear programming and we show that loopdependent mobile offset alignment be sometimes necessary for optimum performance we describe a algorithm with for determine mobile alignment for object within do loop we also identify situation in which replicate alignment be either require by the program itself or can be use to improve performance we describe a algorithm base on network flow that replicate object so as to minimize the total amount of broadcast communication in replication doi 101006 jpdc 19960137 control flow adg number of ways contraction operand	J._Parallel_Distrib._Comput.	
988827	john_r._gilbert robert_schreiber	optimal expression evaluation for datum parallel architecture		J._Parallel_Distrib._Comput.	
1038154	robert_schreiber	high performance fortran version 2		Parallel_Processing_Letters	
1073300	robert_schreiber piyush_mehrotra	high performance fortran come of age guest editors introduction		Scientific_Programming	
1078852	alain_darte robert_schreiber gilles_villard	latticebased memory allocation	this work extend	IEEE_Trans._Computers	LIP Ecole_Normale_Superieure_de_Lyon France
1085057	scott_a._mahlke rajiv_a._ravindran michael_s._schlansker robert_schreiber timothy_sherwood	bitwidth cognizant architecture synthesis of custom hardwareaccelerator	pico be a system for automatically synthesize embedded hardware accelerator from loop nest specii in the c programming language a key issue confront when design such accelerator be the optimization of hardware by exploit information that be know about the vary number of bit require to represent and process operand in this paper we describe the handling and exploitation of integer bitwidth in pico a bitwidth analysis procedure be use to determine bitwidth requirement for all integer variable and operation in a c application give known bitwidth for all variable complex problem arise when determine a program schedule that speciie on which function unit and at what time each operation execute if operation be assign to function unit with no knowledge of bitwidth bitwidthrelated cost beneet be lose when each unit be build to accommodate the widest operation assign by carefully place operation of similar width on the same unit hardware cost be decrease this problem be address use a preliminary clustering of operation that be base jointly on width and implementation cost these cluster be then honor during resource allocation and operation scheduling to create a eecient widthconscious design experimental result show that exploit integer bitwidth substantially reduce the gate count of picosynthesized hardware accelerator across a range of application doi 101109 43959864 bitwidth accelerator pico operand fus	IEEE_Trans._on_CAD_of_Integrated_Circuits_and_Systems	
1117745	alain_darte robert_schreiber b._ramakrishna_rau frederic_vivien	construct and exploit linear schedule with prescribe parallelism	we present two new result of importance in code generation for and synthesis of synchronously schedule parallel processor array and multicluster vliw the first be a new practical method for construct a linear schedule for the iteration of a loop nest that schedule precisely one iteration per cycle on each of a prescribe set of processor while this problem go back to the era in which systolic computation be in vogue it have defy practical solution until now we provide a closed form solution that enable the enumeration of all such schedule the second result be a new technique that reduce the cost of code or hardware whose function be to control the flow of datum and predicate operation and to generate memory address the key idea be that by use the mathematical structure of any of the conflictfree schedule we construct a very shallow recurrence can be develop to inexpensively update these quantity doi 101145 504914504921 partitioning processor array linear schedule	ACM_Trans._Design_Autom._Electr._Syst.	Hewlett-Packard_Company Palo_Alto CA
1123417	siddhartha_chatterjee john_r._gilbert robert_schreiber shang-hua_teng	optimal evaluation of array expression on massively parallel machine	we investigate the problem of optimal evaluation of fortran90 style array expression on a massively parallel distributedmemory machine on such machine a elementwise operation can be perform in unit time for array whose corresponding element be in the same processor if the array be not align in this manner the cost of alignment be part of the cost of expression evaluation the choice of where to perform the operation then affect this cost we demonstrate how a dynamic programming technique can be apply to solve this problem efficiently for a wide variety of interconnection scheme include multidimensional grid and ring hypercube and fattree we also consider the variant where the operation may change the shape of the array and show that we approach extend naturally to handle this case doi 101145 156668156693 parallel machine array expression communication cost expression tree embedding	ACM_Trans._Program._Lang._Syst.	
1165510	michael_j._schulte shuvra_s._bhattacharyya robert_schreiber	guest editorial	the purpose of this meeting be to present and to discuss the current and future state of the rapidly develop field of separation technology with its ca 200 participant from various country the symposium be successful the organizer would like to thank all participant for they contribution and the author for the preparation of the manuscript which be now available in this special issue and professor bill koros for give we the opportunity to publish these papers i hope to see all active membrane technologist again at we next conference which will be hold 2327 june 1997 elsevier science bv	VLSI_Signal_Processing	
1165879	robert_schreiber shail_aditya scott_a._mahlke vinod_kathail b._ramakrishna_rau darren_c._cronquist mukund_sivaraman	piconpa highlevel synthesis of nonprogrammable hardware accelerators	highlevel synthesis asic systolic array the piconpa system automatically synthesize nonprogrammable accelerator lrb npa rrb to be use as coprocessor for function express as loop nest in c the npa it generate consist of a synchronous array of one or more customize processor datapath they controller local memory and interface the user or a design space exploration tool that be a part of the full pico system identify within the application a loop nest to be implement as a npa and indicate the performance require of the npa by specify the number of processor and the number of machine cycle that each processor use per iteration of the inner loop piconpa emit synthesizable hdl that define the accelerator at the register transfer level lrb rtl rrb the system also modify the user s application software to make use of the generate accelerator the main objective of piconpa be to reduce design cost and time without significantly reduce design quality design of a npa and its support software typically require one or two week use piconpa which be a manyfold improvement over the industry norm in addition piconpa can readily generate a widerange of implementation with scalable performance from a single specification in experimental comparison of npa of equivalent throughput piconpa design be slightly more costly than handdesigned accelerator logic synthesis and placeandroute have be perform successfully on piconpa design which have achieve high clock rate abstract the piconpa system automatically synthesize nonprogrammable accelerator lrb npa rrb to be use as coprocessor for function express as loop nest in c the npa it generate consist of a synchronous array of one or more customize processor datapath they controller local memory and interface the user or a design space exploration tool that be a part of the full pico system identify within the application a loop nest to be implement as a npa and indicate the performance require of the npa by specify the number of processor and the number of machine cycle that each processor use per iteration of the inner loop piconpa emit synthesizable hdl that define the accelerator at the register transfer level lrb rtl rrb the system also modify the user s application software to make use of the generate accelerator the main objective of piconpa be to reduce design cost and time without significantly reduce design quality design of a npa and its support software typically require one or two week use piconpa which be a manyfold doi 101023 a 1015341305426 asic loop nest accelerator pico npa	VLSI_Signal_Processing	Hewlett-Packard_Laboratories Palo_Alto California_94304-1126 USA
1295506	ken_kennedy charles_koelbel robert_schreiber	define and measure the productivity of programming languages	the overall objective of programming support system be to make it possible to produce software faster with the same workforce with no degradation and possibly a improvement in software quality generally there be two way to approach this goal first we can increase the effectiveness of individual application developer by provide programming language and tool that enhance programming productivity second we can broaden the community of application developer by make programming more accessible as it happen the use of higherlevel language and programming interface support both these strategy by incorporate a higher level of abstraction such language make application development both easier and faster lrb for the purpose of this paper we will define programming language to encompass the entire toolset language compiler debugger tuning tool associate with the language rrb we must however ensure that these advantage do not come at the cost of performance program write in a highlevel language and intend to solve large problem on highly parallel machine must not be egregiously less efficient than the same application write in a lowerlevel language if they be then the language be unlikely to be accept because this have be a traditional stumbling block for highlevel language we productivity analysis must incorporate metric of both programming effort and performance furthermore these metric must be link so that the tradeoff between language power and program efficiency can be evaluate properly similarly if highlevel language be to be accept program write in they can not exhibit more fault consume more memory or be less portable than if write in lowlevel competitor fortunately these have not be troublesome issue in the past so we feel justified in not address they headon in this paper although we do feel that such factor should be investigate in the future thus for any give development task each programming language must be evaluate with respect to at least two criterion the time and effort require to write debug and tune the code and the performance of the code that result the goal of this paper be to define these two evaluation metric clearly and unambiguously and to propose method by which to measure they nbchc020087 opinion interpretation conclusion and recommendation be those of the author and be not necessarily endorse by the united states government doi 101177 1094342004048537 highlevel language	IEEE/ACM_Transactions_on_Networking_(TON)	Advanced_Computer_Systems_Laboratory_at_Hewlett_Packard_Laboratories
1325038	dana_vantrease nathan_l._binkert robert_schreiber mikko_h._lipasti	light speed arbitration and flow control for nanophotonic interconnect	by provide high bandwidth chipwide communication at low latency and low power onchip optics can improve manycore performance dramatically optical channel that connect many node and allow for single cycle cacheline transmission will require fast high bandwidth arbitration we exploit cmo nanophotonic device to create arbiter that meet the demand of onchip optical interconnect we accomplish this by exploit a unique property of optical device that allow arbitration to scale with latency bound by the time of flight of light through a silicon waveguide that pass all requester we explore two class of distribute tokenbased arbitration channel base and slot base and tailor they to optics channel base protocol allocate a entire waveguide to one requester at a time whereas slot base protocol allocate fix size slot in the waveguide simple optical protocol suffer from a fix prioritization of user and can starve those with low priority we correct this with new scheme that vary the priority dynamically to ensure fairness on a 64node optical interconnect under uniform random singlecycle traffic we fair slot protocol achieve 74 channel utilization while we fair channel protocol achieve 45 ours be the first arbitration protocol that exploit optics to simultaneously achieve low latency high utilization and fairness doi 101145 16691121669152 crosstalk slot arbitration waveguide token	null	HP_Laboratories
1339036	robert_schreiber zeyu_li harlyn_baker	robust software for computing camera motion parameters	camera motion parameter we revisit the method of tsai huang and zhu for the computation of camera motion parameter in computer vision we elucidate some spectral property of the homography matrix that arise which be rankone perturbation of rotation matrix we show how to correct for noise by find the rankone perturbation of a rotation closest to a give matrix we illustrate some of the inaccuracy and computational failure that can arise when use the formula give by tsai and we propose new formula that avoid these pitfall a computational experiment show that the new method be indeed quite robust abstract we revisit the method of tsai huang and zhu for the computation of camera motion parameter in computer vision we elucidate some spectral property of the homography matrix that arise which be rankone perturbation of rotation matrix we show how to correct for noise by find the rankone perturbation of a rotation closest to a give matrix we illustrate some of the inaccuracy and computational failure that can arise when use the formula give by tsai and we propose new formula that avoid these pitfall a computational experiment show that the new method be indeed quite robust doi 101007 s1085100801061 inaccuracy rankone perturbation pitfall scaling motion parameter	Journal_of_Mathematical_Imaging_and_Vision	
1446006	david_e._foulser robert_schreiber	the saxpy matrix1 a generalpurpose systolic computer		Computer	Saxpy_Computer_Corporation
1447316	robert_schreiber beresford_parlett	block reflector theory and computation		SIAM_Journal_on_Numerical_Analysis	Rensselaer_Polytechnic_Institute Troy NY
1453683	lars_eld√©n robert_schreiber	a aplicaiton of systolic array to linear discrete ill pose problem		SIAM_Journal_on_Scientific_and_Statistical_Computing	
1453813	robert_schreiber	computing generalize inverse and eigenvalue of symmetric matrix use sytolic array	a thesis submit for the degree of master of apply science in computer and information science in the school of computer and information science this thesis contain no material which have be accept for the award of any other degree or diploma in any university and to the best of my knowledge and belief it contain no material previously publish or write by another person except where due reference be give in the text of the thesis i consent to the thesis be make available for photocopy and loan of it be accept for the award of the degree ii to pat iii acknowledgements this thesis would not have be possible without the support and encouragement of certain people who contribute lrb and do not contribute rrb to the environment in which it be write apology to anyone i have miss first of all i would like to thank my supervisor dr john asenstorfer for he support and advice throughout this work and for the many suggestion and improvement he make i also would like to thank those people who so generously volunteer to proof read various draft of this thesis in particular mr for the various comment and suggestion they make finally i would like to thank my family my partner and my friend for they continual encouragement and support they have all show i throughout this undertaking the idea for this work be give in a private communication from mr a abstract since systolic array be rst propose by h t kung and c e leiserson in 1978 one of the major problem have be how can a algorithm be implement on a array as fast and as easily as possible the study describe in this thesis present a consideration of the problem of implement the gramschmidt orthogonalization lrb gso rrb method for matrix of arbitrary order this be achieve on a xed size systolic array which have a software library of matrix operator as a interface the algorithm be write in term of matrix operator which contrast with the usual vector form to be find in many source the performance of the systolic algorithm be evaluate use a systolic simulation system that be develop by the author the report work in this thesis show that a versatile matrix interface use a suite of matrix function write in a exist language lrb in this case the c programming language rrb be a good approach	Proc._of_the_sixth_int'l._symposium_on_Computing_methods_in_applied_sciences_and_engineering,_VI	Stanford_Univ. Stanford CA
1467721	robert_schreiber wei-pai_tang	on systolic array for update the cholesky factorization		BIT	The_Royal_Institute_of_Technology Stockholm Sweden
1498685	yan_huo robert_schreiber	efficient massively parallel eigenvalue computation		International_Journal_of_Supercomputer_Applications_and_High_Performance_Engineering	
1504820	siddhartha_chatterjee john_r._gilbert robert_schreiber shang-hua_teng	optimal evaluation of array expression on massively parallel machine lrb extend abstract rrb	we investigate the problem of optimal evaluation of fortran90 style array expression on a massively parallel distributedmemory machine on such machine a elementwise operation can be perform in unit time for array whose corresponding element be in the same processor if the array be not align in this manner the cost of alignment be part of the cost of expression evaluation the choice of where to perform the operation then affect this cost we demonstrate how a dynamic programming technique can be apply to solve this problem efficiently for a wide variety of interconnection scheme include multidimensional grid and ring hypercube and fattree we also consider the variant where the operation may change the shape of the array and show that we approach extend naturally to handle this case doi 101145 156668156693 parallel machine array expression communication cost expression tree embedding	ACM_SIGPLAN_Notices	
1507075	siddhartha_chatterjee john_r._gilbert fred_j._e._long robert_schreiber shang-hua_teng	generating local address and communication set for dataparallel program	generating local address and communication set be a important issue in distributedmemory implementation of dataparallel language such as high performance fortran we show that for a array italic a italic affinely align to a italic template italic that be distribute across italic p italic processor with a italic cyclic lrb k rrb italic distribution and a computation involve the regular section italic a lrb l h s rrb italic the local memory access sequence for any processor be characterize by a finite state machine of at most italic k italic state we present fast algorithm for compute the essential information about these state machine and extend the framework to handle multidimensional array we also show how to generate communication set use the state machine approach performance result show that this solution require very little runtime overhead and acceptable preprocessing time doi 101145 155332155348 hpf fsm communication set array element stride	ACM_SIGPLAN_Notices	Research_Institute_for_Advanced_Computer_Science_(RIACS NASA_Ames_Research_Center Moffett_Field CA
1510627	fernando_l._alvarado robert_schreiber	optimal parallel solution of sparse triangular system		SIAM_Journal_on_Scientific_Computing	
1545461	edward_rothberg robert_schreiber	efficient method for outofcore sparse cholesky factorization	sparse matrix memory hierarchy cholesky factorization we consider the problem of sparse cholesky factorization with limited main memory the goal be to efficiently factor matrix whose cholesky factor essentially fill the available disk storage use very little memory lrb as little as 16 mbyte rrb this would enable very large industrial problem to be solve with workstation of very modest cost we consider three candidate algorithm each be base on a partitioning of the matrix into panel the first be a robust outofcore multifrontal method that keep the factor the stack and the large frontal matrix on disk the other be leftlooking method we find that straightforward implementation of all of they suffer from excessive disk io for large problem that arise in interiorpoint algorithm for linear programming we introduce several improvement to these simple outofcore method and find that a leftlooking method that nevertheless use the multifrontal algorithm for portion of the matrix lrb subtree of the supernodal elimination tree whose multifrontal stack fit in memory rrb be very effective with 32 mbyte of main memory it achieve over 77 percent of its incore performance on all but one of we twelve test matrix lrb 67 percent in that one case rrb even though the size of the factor be in all case hundred of million or even billion of byte abstract we consider the problem of sparse cholesky factorization with limited main memory the goal be to eeciently factor matrix whose cholesky factor essentially ll the available disk storage use very little memory as little as 16 mbyte this would enable very large industrial problem to be solve with workstation of very modest cost we consider three candidate algorithm each be base on a partitioning of the matrix into panel the rst be a robust outofcore multifrontal method that keep the factor the stack and the large frontal matrix on disk the other be leftlooking method we nd that straightforward implementation of all of they suuer from excessive disk iio for large problem that arise in interiorpoint algorithm for linear programming we introduce several improvement to these simple outofcore method and nd that a leftlooking method that nevertheless use the multifrontal algorithm for portion of the matrix subtree of the supernodal elimination tree whose multifrontal stack t in memory be very eeective with 32 mbyte of main memory it achieve over 77 percent of its incore performance on all but one of we twelve doi 101137 s1064827597322975 frontal large incore disk factorization	SIAM_Journal_on_Scientific_Computing	
1576010	robert_schreiber	a new implementation of sparse gaussian elimination	a lmplementat rsb on of sparse ldl t and lu factorlzatlon and back substitution base on a new scheme for store sparse matrme be present the new method appear to be as efficmnt m term of work and storage as exist scheme it be more amenable to efficmnt implementation on fast plpehned scmntlfic computer doi 101145 356004356006 elimination tree sparse matrix factorization matrix row elimination forest	ACM_Transactions_on_Mathematical_Software_(TOMS)	Department_of_Computer_Science Stanford_University Stanford CA
1645702	gautham_shroff robert_schreiber	on the convergence of the cyclic jacobi method for parallel block ordering	cyclic coordinate descent be a classic optimization method that have witness a resurgence of interest in signal processing statistics and machine learning reason for this renew interest include the simplicity speed and stability of the method as well as its competitive performance on 1 regularize smooth optimization problem surprisingly very little be know about its nonasymptotic convergence behavior on these problem most exist result either just prove convergence or provide asymptotic rate we fill this gap in the literature by prove o lrb 1k rrb convergence rate lrb where k be the iteration count rrb for two variant of cyclic coordinate descent under a isotonicity assumption we analysis proceeds by compare the objective value attain by the two variant with each other as well as with the gradient descent algorithm we show that the iterate generate by the cyclic coordinate descent method remain better than those of gradient descent uniformly over time 1 introduction as we encounter larger and higher dimensional dataset we be face with novel challenge in design and analyze optimization algorithm that can work efficiently with such dataset this paper consider one such class of algorithm namely cyclic coordinate descent and variant thereof there have be recent work demonstrate the potential of these algorithm for solve large and high dimensional 1regularized loss minimization problem doi 101137 110840054	SIAM_Journal_on_Matrix_Analysis_and_Applications	
1670021	john_r._gilbert robert_schreiber	highly parallel sparse cholesky factorization	we develop and compare several negrained parallel algorithm to compute the cholesky factorization of a sparse matrix we experimental implementation be on the connection machine a distributedmemory simd machine whose programming model conceptually supply one processor per data element in contrast to specialpurpose algorithm in which the matrix structure conform to the connection structure of the machine we focus be on matrix with arbitrary sparsity structure the most promising alternativeis a supernodal multifrontalalgorithmwhose inner loop perform several dense factorization simultaneously on a twodimensional grid of processor a negrained parallel dense factorization algorithm be use as the key subroutine the sparse code attain execution rate comparable to those of the dense subroutine although at present architectural limitation prevent the dense factorization from realize its potential eeciency we conclude that a regular datum parallel architecture can be use eeciently to solve arbitrarily structure sparse problem we also present a performance model and use it to analyze we algorithm we nd that asymptotic analysis combine with experimental measurement of parameter be accurate enough to be useful in choose among alternative algorithm for a complicated problem doi 101137 0913067 nasa complicated inner loop regularity eeciency	SIAM_Journal_on_Scientific_and_Statistical_Computing	
1675233	victor_pan robert_schreiber	a improve newton interaction for the generalize inverse of a matrix with application	the development of legged robot for complex environment require controller that guarantee both high tracking performance and compliance with the environment more specifically the control of the contact interaction with the environment be of crucial importance to ensure stable robust and safe motion in this contribution we develop a inversedynamics controller for floatingbase robot under contact constraint that can minimize any combination of linear and quadratic cost in the contact constraint and the command we main result be the exact analytical derivation of the controller such a result be particularly relevant for legged robot as it allow we to use torque redundancy to directly optimize contact interaction for example give a desire locomotion behavior we can guarantee the minimization of contact force to reduce slip on difficult terrain while ensure high tracking performance of the desire motion the main advantage of the controller be its simplicity computational efficiency and robustness to model inaccuracy we present detailed experimental result on simulated humanoid and quadruped robot as well as a real quadruped robot the experiment demonstrate that the controller can greatly improve the robustness of locomotion of the robot doi 101177 0278364912469821 command contact force contact constraint legged robot torque	SIAM_Journal_on_Scientific_and_Statistical_Computing	
1683612	robert_schreiber horst_d._simon	towards the teraflops capability for cfd	we be survey current project in the area of parallel supercomputer the machine consider here will become commercially available in the 19901992 time frame all be suitable for explore the critical issue in apply parallel processor to large scale scientific computation in particular cfd calculation this report present a overview of the survey machine and a detailed analysis of the various architectural and technology approach take particular emphasis be place on the feasibility of a teraflops capability follow the path propose by various developer this a revision of a internal nas document which have be write originally in spring of 1990 and revise for publication as a book chapter in spring of 1992 1 introduction in the last several year a wide variety of parallel machine have become available for explore the issue of use parallelism in scientific computing whereas most of the early lrb zeroth generation rrb machine from 1983 to 1987 be rather experimental in nature and serve mainly for research investigation in area such as algorithm language operate system for parallel computing in 1988 and 1989 several member of a first generation of parallel supercomputer become available we want to use the term supercomputer here because these parallel supercomputer such as the current cm2 and intel touchstone gamma machine be in they larger configuration comparable both in memory and peak computational speed to the performance of the most powerful conventional supercomputer eg the cray ymp however it be well know that these machine be still very deficient in they system aspect for example in they ability to handle a large number of user today 3 we be at the threshold to a second generation of parallel supercomputer which offer order of magnitude improvement in computational power over the previous generation as well as a improve software and user environment because of they considerable potential computational power parallel supercomputer be increasingly consider as a alternative to the more conventional supercomputer base on a small number of powerful vector processor even though many research issue concern they effective use and they integration into a large scale production facility be still unresolved parallel supercomputer be already use for production computing although mostly in a single application mode	Parallel_computational_fluid_dynamics:_implementations_and_results	
1684055	john_r._gilbert cleve_moler robert_schreiber	sparse matrix in matlab design and implementation	we have extend the matrix computation language and environment matlab to include sparse matrix storage and operation the only change to the outward appearance of the matlab language be a pair of command to create full or sparse matrix nearly all the operation of matlab now apply equally to full or sparse matrix without any explicit action by the user the sparse datum structure represent a matrix in space proportional to the number of nonzero entry and most of the operation compute sparse result in time proportional to the number of arithmetic operation on nonzero	SIAM_Journal_on_Matrix_Analysis_and_Applications	
1713221	siddhartha_chatterjee john_r._gilbert fred_j._e._long robert_schreiber shang-hua_teng	generating local address and communication set for dataparallel program	generating local address and communication set be a important issue in distributedmemory implementation of dataparallel language such as high performance fortran we show that for a array italic a italic affinely align to a italic template italic that be distribute across italic p italic processor with a italic cyclic lrb k rrb italic distribution and a computation involve the regular section italic a lrb l h s rrb italic the local memory access sequence for any processor be characterize by a finite state machine of at most italic k italic state we present fast algorithm for compute the essential information about these state machine and extend the framework to handle multidimensional array we also show how to generate communication set use the state machine approach performance result show that this solution require very little runtime overhead and acceptable preprocessing time doi 101145 155332155348 hpf fsm communication set array element stride	Journal_of_Parallel_and_Distributed_Computing	
